{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "022a58e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/591753] Tokenizing captions...\n",
      "[100000/591753] Tokenizing captions...\n",
      "[200000/591753] Tokenizing captions...\n",
      "[300000/591753] Tokenizing captions...\n",
      "[400000/591753] Tokenizing captions...\n",
      "[500000/591753] Tokenizing captions...\n",
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 591753/591753 [00:40<00:00, 14475.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 128          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = False   # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512        \n",
    "# number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() #if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5359e3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/4624], Loss: 4.3252, Perplexity: 75.5804869\n",
      "Epoch [1/3], Step [200/4624], Loss: 3.8964, Perplexity: 49.22278\n",
      "Epoch [1/3], Step [300/4624], Loss: 4.1968, Perplexity: 66.47598\n",
      "Epoch [1/3], Step [400/4624], Loss: 3.7898, Perplexity: 44.2477\n",
      "Epoch [1/3], Step [500/4624], Loss: 3.3964, Perplexity: 29.8559\n",
      "Epoch [1/3], Step [600/4624], Loss: 3.9209, Perplexity: 50.4442\n",
      "Epoch [1/3], Step [700/4624], Loss: 2.9790, Perplexity: 19.6681\n",
      "Epoch [1/3], Step [800/4624], Loss: 3.1695, Perplexity: 23.7958\n",
      "Epoch [1/3], Step [900/4624], Loss: 3.6946, Perplexity: 40.2302\n",
      "Epoch [1/3], Step [1000/4624], Loss: 3.0262, Perplexity: 20.6177\n",
      "Epoch [1/3], Step [1100/4624], Loss: 2.8274, Perplexity: 16.9022\n",
      "Epoch [1/3], Step [1200/4624], Loss: 2.9885, Perplexity: 19.85627\n",
      "Epoch [1/3], Step [1300/4624], Loss: 2.9350, Perplexity: 18.8213\n",
      "Epoch [1/3], Step [1400/4624], Loss: 3.5940, Perplexity: 36.3810\n",
      "Epoch [1/3], Step [1500/4624], Loss: 2.7146, Perplexity: 15.0982\n",
      "Epoch [1/3], Step [1600/4624], Loss: 2.6468, Perplexity: 14.1090\n",
      "Epoch [1/3], Step [1700/4624], Loss: 2.7353, Perplexity: 15.4143\n",
      "Epoch [1/3], Step [1800/4624], Loss: 2.7375, Perplexity: 15.4477\n",
      "Epoch [1/3], Step [1900/4624], Loss: 2.4724, Perplexity: 11.8509\n",
      "Epoch [1/3], Step [2000/4624], Loss: 2.6940, Perplexity: 14.7900\n",
      "Epoch [1/3], Step [2100/4624], Loss: 2.6461, Perplexity: 14.0984\n",
      "Epoch [1/3], Step [2200/4624], Loss: 3.6796, Perplexity: 39.6286\n",
      "Epoch [1/3], Step [2300/4624], Loss: 2.5326, Perplexity: 12.5860\n",
      "Epoch [1/3], Step [2400/4624], Loss: 2.5119, Perplexity: 12.3288\n",
      "Epoch [1/3], Step [2500/4624], Loss: 2.6911, Perplexity: 14.7482\n",
      "Epoch [1/3], Step [2600/4624], Loss: 2.5544, Perplexity: 12.8640\n",
      "Epoch [1/3], Step [2700/4624], Loss: 2.2690, Perplexity: 9.66931\n",
      "Epoch [1/3], Step [2800/4624], Loss: 2.3591, Perplexity: 10.5811\n",
      "Epoch [1/3], Step [2900/4624], Loss: 2.4617, Perplexity: 11.7253\n",
      "Epoch [1/3], Step [3000/4624], Loss: 2.5934, Perplexity: 13.3755\n",
      "Epoch [1/3], Step [3100/4624], Loss: 2.4231, Perplexity: 11.2806\n",
      "Epoch [1/3], Step [3200/4624], Loss: 2.5585, Perplexity: 12.9164\n",
      "Epoch [1/3], Step [3300/4624], Loss: 2.4179, Perplexity: 11.2221\n",
      "Epoch [1/3], Step [3400/4624], Loss: 2.4607, Perplexity: 11.7132\n",
      "Epoch [1/3], Step [3500/4624], Loss: 2.8957, Perplexity: 18.0965\n",
      "Epoch [1/3], Step [3600/4624], Loss: 2.2312, Perplexity: 9.31135\n",
      "Epoch [1/3], Step [3700/4624], Loss: 2.4165, Perplexity: 11.2065\n",
      "Epoch [1/3], Step [3800/4624], Loss: 2.5263, Perplexity: 12.5068\n",
      "Epoch [1/3], Step [3900/4624], Loss: 2.4120, Perplexity: 11.1563\n",
      "Epoch [1/3], Step [4000/4624], Loss: 2.4944, Perplexity: 12.1140\n",
      "Epoch [1/3], Step [4100/4624], Loss: 2.3847, Perplexity: 10.8556\n",
      "Epoch [1/3], Step [4200/4624], Loss: 2.6320, Perplexity: 13.9012\n",
      "Epoch [1/3], Step [4300/4624], Loss: 2.7558, Perplexity: 15.7335\n",
      "Epoch [1/3], Step [4400/4624], Loss: 2.4132, Perplexity: 11.1692\n",
      "Epoch [1/3], Step [4500/4624], Loss: 2.3962, Perplexity: 10.9813\n",
      "Epoch [1/3], Step [4600/4624], Loss: 2.4171, Perplexity: 11.2133\n",
      "Epoch [2/3], Step [100/4624], Loss: 2.2187, Perplexity: 9.195853\n",
      "Epoch [2/3], Step [200/4624], Loss: 2.8309, Perplexity: 16.9614\n",
      "Epoch [2/3], Step [300/4624], Loss: 2.3252, Perplexity: 10.2288\n",
      "Epoch [2/3], Step [400/4624], Loss: 2.1743, Perplexity: 8.79564\n",
      "Epoch [2/3], Step [500/4624], Loss: 2.2692, Perplexity: 9.67178\n",
      "Epoch [2/3], Step [600/4624], Loss: 2.5991, Perplexity: 13.4515\n",
      "Epoch [2/3], Step [700/4624], Loss: 2.4171, Perplexity: 11.2133\n",
      "Epoch [2/3], Step [800/4624], Loss: 2.3995, Perplexity: 11.0172\n",
      "Epoch [2/3], Step [900/4624], Loss: 2.2577, Perplexity: 9.56116\n",
      "Epoch [2/3], Step [1000/4624], Loss: 3.1987, Perplexity: 24.4997\n",
      "Epoch [2/3], Step [1100/4624], Loss: 2.2896, Perplexity: 9.87128\n",
      "Epoch [2/3], Step [1200/4624], Loss: 2.2347, Perplexity: 9.34400\n",
      "Epoch [2/3], Step [1300/4624], Loss: 2.5038, Perplexity: 12.2284\n",
      "Epoch [2/3], Step [1400/4624], Loss: 2.3108, Perplexity: 10.0830\n",
      "Epoch [2/3], Step [1500/4624], Loss: 2.2793, Perplexity: 9.77017\n",
      "Epoch [2/3], Step [1600/4624], Loss: 2.2166, Perplexity: 9.17578\n",
      "Epoch [2/3], Step [1700/4624], Loss: 2.3838, Perplexity: 10.8466\n",
      "Epoch [2/3], Step [1800/4624], Loss: 2.1959, Perplexity: 8.98838\n",
      "Epoch [2/3], Step [1900/4624], Loss: 2.5478, Perplexity: 12.7785\n",
      "Epoch [2/3], Step [2000/4624], Loss: 2.3415, Perplexity: 10.3972\n",
      "Epoch [2/3], Step [2100/4624], Loss: 2.3707, Perplexity: 10.7048\n",
      "Epoch [2/3], Step [2200/4624], Loss: 2.1155, Perplexity: 8.29363\n",
      "Epoch [2/3], Step [2300/4624], Loss: 2.1929, Perplexity: 8.96129\n",
      "Epoch [2/3], Step [2400/4624], Loss: 2.0873, Perplexity: 8.06320\n",
      "Epoch [2/3], Step [2500/4624], Loss: 2.3688, Perplexity: 10.6845\n",
      "Epoch [2/3], Step [2600/4624], Loss: 2.5200, Perplexity: 12.4282\n",
      "Epoch [2/3], Step [2700/4624], Loss: 2.1835, Perplexity: 8.87756\n",
      "Epoch [2/3], Step [2800/4624], Loss: 2.5238, Perplexity: 12.4757\n",
      "Epoch [2/3], Step [2900/4624], Loss: 2.1355, Perplexity: 8.46151\n",
      "Epoch [2/3], Step [3000/4624], Loss: 2.1531, Perplexity: 8.61191\n",
      "Epoch [2/3], Step [3100/4624], Loss: 2.9480, Perplexity: 19.0686\n",
      "Epoch [2/3], Step [3200/4624], Loss: 2.3398, Perplexity: 10.3791\n",
      "Epoch [2/3], Step [3300/4624], Loss: 2.2757, Perplexity: 9.73514\n",
      "Epoch [2/3], Step [3400/4624], Loss: 2.1577, Perplexity: 8.65145\n",
      "Epoch [2/3], Step [3500/4624], Loss: 2.4307, Perplexity: 11.3672\n",
      "Epoch [2/3], Step [3600/4624], Loss: 2.2059, Perplexity: 9.07818\n",
      "Epoch [2/3], Step [3700/4624], Loss: 2.1334, Perplexity: 8.44344\n",
      "Epoch [2/3], Step [3800/4624], Loss: 2.2591, Perplexity: 9.57489\n",
      "Epoch [2/3], Step [3900/4624], Loss: 2.1279, Perplexity: 8.39691\n",
      "Epoch [2/3], Step [4000/4624], Loss: 2.2086, Perplexity: 9.10273\n",
      "Epoch [2/3], Step [4100/4624], Loss: 2.1152, Perplexity: 8.29161\n",
      "Epoch [2/3], Step [4200/4624], Loss: 2.1239, Perplexity: 8.36400\n",
      "Epoch [2/3], Step [4300/4624], Loss: 2.3546, Perplexity: 10.5337\n",
      "Epoch [2/3], Step [4400/4624], Loss: 2.2819, Perplexity: 9.79515\n",
      "Epoch [2/3], Step [4500/4624], Loss: 2.4629, Perplexity: 11.7388\n",
      "Epoch [2/3], Step [4600/4624], Loss: 2.7186, Perplexity: 15.1588\n",
      "Epoch [3/3], Step [100/4624], Loss: 2.3699, Perplexity: 10.69602\n",
      "Epoch [3/3], Step [200/4624], Loss: 2.1792, Perplexity: 8.83883\n",
      "Epoch [3/3], Step [300/4624], Loss: 2.2826, Perplexity: 9.80258\n",
      "Epoch [3/3], Step [400/4624], Loss: 2.1880, Perplexity: 8.91702\n",
      "Epoch [3/3], Step [500/4624], Loss: 2.3330, Perplexity: 10.3092\n",
      "Epoch [3/3], Step [600/4624], Loss: 2.1625, Perplexity: 8.69266\n",
      "Epoch [3/3], Step [700/4624], Loss: 2.0019, Perplexity: 7.40323\n",
      "Epoch [3/3], Step [800/4624], Loss: 2.1831, Perplexity: 8.87396\n",
      "Epoch [3/3], Step [900/4624], Loss: 2.1022, Perplexity: 8.18439\n",
      "Epoch [3/3], Step [1000/4624], Loss: 2.1387, Perplexity: 8.4887\n",
      "Epoch [3/3], Step [1100/4624], Loss: 2.2698, Perplexity: 9.67757\n",
      "Epoch [3/3], Step [1200/4624], Loss: 2.3016, Perplexity: 9.99035\n",
      "Epoch [3/3], Step [1300/4624], Loss: 2.3366, Perplexity: 10.3462\n",
      "Epoch [3/3], Step [1400/4624], Loss: 2.1214, Perplexity: 8.34282\n",
      "Epoch [3/3], Step [1500/4624], Loss: 2.1937, Perplexity: 8.96812\n",
      "Epoch [3/3], Step [1600/4624], Loss: 2.2057, Perplexity: 9.07629\n",
      "Epoch [3/3], Step [1700/4624], Loss: 2.2108, Perplexity: 9.12297\n",
      "Epoch [3/3], Step [1800/4624], Loss: 2.1038, Perplexity: 8.19692\n",
      "Epoch [3/3], Step [1900/4624], Loss: 2.2162, Perplexity: 9.17242\n",
      "Epoch [3/3], Step [2000/4624], Loss: 2.1404, Perplexity: 8.50257\n",
      "Epoch [3/3], Step [2100/4624], Loss: 2.0143, Perplexity: 7.49561\n",
      "Epoch [3/3], Step [2200/4624], Loss: 2.1052, Perplexity: 8.20891\n",
      "Epoch [3/3], Step [2300/4624], Loss: 1.9573, Perplexity: 7.08051\n",
      "Epoch [3/3], Step [2400/4624], Loss: 2.1288, Perplexity: 8.40507\n",
      "Epoch [3/3], Step [2500/4624], Loss: 2.2441, Perplexity: 9.43190\n",
      "Epoch [3/3], Step [2600/4624], Loss: 1.9887, Perplexity: 7.30603\n",
      "Epoch [3/3], Step [2700/4624], Loss: 2.1123, Perplexity: 8.26738\n",
      "Epoch [3/3], Step [2800/4624], Loss: 2.1776, Perplexity: 8.82502\n",
      "Epoch [3/3], Step [2900/4624], Loss: 2.0225, Perplexity: 7.55712\n",
      "Epoch [3/3], Step [3000/4624], Loss: 2.0396, Perplexity: 7.68740\n",
      "Epoch [3/3], Step [3100/4624], Loss: 2.3288, Perplexity: 10.2655\n",
      "Epoch [3/3], Step [3200/4624], Loss: 2.2520, Perplexity: 9.50657\n",
      "Epoch [3/3], Step [3300/4624], Loss: 2.0119, Perplexity: 7.47755\n",
      "Epoch [3/3], Step [3400/4624], Loss: 2.1378, Perplexity: 8.48091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Step [3500/4624], Loss: 2.1766, Perplexity: 8.81660\n",
      "Epoch [3/3], Step [3600/4624], Loss: 2.3881, Perplexity: 10.8923\n",
      "Epoch [3/3], Step [3700/4624], Loss: 2.0044, Perplexity: 7.42207\n",
      "Epoch [3/3], Step [3800/4624], Loss: 2.0154, Perplexity: 7.50408\n",
      "Epoch [3/3], Step [3900/4624], Loss: 2.1204, Perplexity: 8.33417\n",
      "Epoch [3/3], Step [4000/4624], Loss: 2.2195, Perplexity: 9.20293\n",
      "Epoch [3/3], Step [4100/4624], Loss: 2.3253, Perplexity: 10.2292\n",
      "Epoch [3/3], Step [4200/4624], Loss: 2.1610, Perplexity: 8.68013\n",
      "Epoch [3/3], Step [4300/4624], Loss: 2.4098, Perplexity: 11.1314\n",
      "Epoch [3/3], Step [4400/4624], Loss: 2.0600, Perplexity: 7.84587\n",
      "Epoch [3/3], Step [4500/4624], Loss: 2.1039, Perplexity: 8.19845\n",
      "Epoch [3/3], Step [4600/4624], Loss: 2.3446, Perplexity: 10.4288\n",
      "Epoch [3/3], Step [4624/4624], Loss: 2.0171, Perplexity: 7.51683"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "#old_time = time.time()\n",
    "#response = requests.request(\"GET\", \n",
    "#                           \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "#                           headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        #if time.time() - old_time > 60:\n",
    "        #   old_time = time.time()\n",
    "        #    requests.request(\"POST\", \n",
    "        #                    \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "        #                    headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cec9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
